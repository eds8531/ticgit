{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dictionary.com/browse/'\n",
    "word = 'ape'\n",
    "\n",
    "# Cert locale: '/Users/ericschlosser/Desktop/TheHardWay/GRE_Scraper_Support/dictionary.com.cer'\n",
    "# 'css-irpbha e7pf46o0'\n",
    "results = requests.get(url + word, verify = False)\n",
    "src = results.content\n",
    "soup = bs(src, 'lxml')\n",
    "\n",
    "pos_list = ['noun', 'verb', 'adjective',  'pronoun', 'adverb', 'preposition', 'conjunction',  'interjection']\n",
    "#text = soup.select('.luna-pos,.one-click-content,.css-1sprl0b,.css-ww67bw,.css-1b1gas3')\n",
    "\n",
    "text = soup.select('.css-nnyc96,.luna-pos')\n",
    "\n",
    "adjs = []\n",
    "for tag in text:\n",
    "    if (tag.text.strip()[0] == tag.text.strip()[0].upper()) & (tag.text.strip()[0] != '('):\n",
    "        adjs.append(tag.text.strip())\n",
    "\n",
    "#print('*****')\n",
    "\n",
    "defs = soup.select('.css-nnyc96')\n",
    "pos = soup.select('.luna-pos')\n",
    "alts = soup.select('.luna-inflected-form')\n",
    "ital = soup.select('.italic')\n",
    "\n",
    "breaks = ['Infor','Dispa', 'Slang']\n",
    "\n",
    "count = True\n",
    "\n",
    "for tag in text:\n",
    "    if tag.text.strip().split(' ')[0] in pos_list:\n",
    "        pos_now = tag.text.strip().split(' ')[0]\n",
    "        count = True\n",
    "    elif tag.text.strip() not in adjs:\n",
    "        if count:\n",
    "            print('pos: ' + pos_now)\n",
    "            print('def: '+ tag.text.strip())\n",
    "    else:\n",
    "        if tag.text.strip()[:5] in breaks:\n",
    "            count = False\n",
    "\n",
    "\n",
    "breaks = ['Informal.','Disparaging and Offensive.']\n",
    "\n",
    "'Other definitions for'\n",
    "\n",
    "dlist = []\n",
    "\n",
    "\n",
    "count = True\n",
    "\n",
    "for tag in text:\n",
    "    #if tag.text.strip()[:5] == 'Slang':\n",
    "    #    pass\n",
    "    #elif tag.text.strip()[:26] == 'Disparaging and Offensive.':\n",
    "    #    pass\n",
    "    if tag in pos:\n",
    "        count = True\n",
    "        dlist.append(tag.text.strip())\n",
    "    \n",
    "    elif tag in defs:\n",
    "        if tag not in ital:\n",
    "            if count:\n",
    "                dlist.append(tag.text.strip())\n",
    "                \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definitions(word_list):\n",
    "    df_word = pd.DataFrame(columns = ['Words', 'Parts of Speech', 'Definitions'])\n",
    "    \n",
    "    url = 'https://www.dictionary.com/browse/'\n",
    "    \n",
    "    pos_list = ['noun', 'verb', 'adjective',  'pronoun', 'adverb', 'preposition', 'conjunction',  'interjection']\n",
    "    breaks = ['Infor','Dispa', 'Slang']\n",
    "    \n",
    "    for word in word_list:\n",
    "        results = requests.get(url + word, verify = False)\n",
    "        src = results.content\n",
    "        soup = bs(src, 'lxml')\n",
    "        text = soup.select('.css-nnyc96,.luna-pos,.css-ww67bw')\n",
    "\n",
    "        adjs = []\n",
    "        for tag in text:\n",
    "            try:\n",
    "                if (tag.text.strip()[0] == tag.text.strip()[0].upper()) & (tag.text.strip()[0] != '('):\n",
    "                    adjs.append(tag.text.strip())\n",
    "            except:\n",
    "                pass\n",
    "        pos = soup.select('.luna-pos')\n",
    "        for tag in text:\n",
    "            print(tag.text.strip())\n",
    "        \n",
    "        count = True\n",
    "        for tag in text:\n",
    "            for character in string.punctuation:\n",
    "                tag_np = tag.text.strip().split(' ')[0].replace(character, '')\n",
    "            if tag_np in pos_list:\n",
    "                pos_now = tag_np\n",
    "                count = True\n",
    "            elif tag.text.strip() not in adjs:\n",
    "                if count:\n",
    "                    defi = tag.text.strip()\n",
    "                    df_word['Definitions'] = [defi]\n",
    "                    df_word['Parts of Speech'] = [pos_now]\n",
    "                    df_word['Words'] = [word]\n",
    "                    try:\n",
    "                        df_tdlist = pd.concat([df_tdlist, df_word], axis = 0, ignore_index = True)\n",
    "                    except:\n",
    "                        df_tdlist = df_word\n",
    "            else:\n",
    "                if tag.text.strip()[:5] in breaks:\n",
    "                    count = False\n",
    "            \n",
    "    df_tdlist.drop_duplicates(inplace = True)\n",
    "    print(df_tdlist)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['blithe']\n",
    "\n",
    "definitions(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = soup.find_all(class_ = ['css-irpbha e7pf46o0','one-click-content css-nnyc96 e1q3nk1v1'])\n",
    "df_tdlist = pd.DataFrame(columns = ['Words', 'Definitions'])\n",
    "#df_tdlist['Words'] = ['space']\n",
    "#df_tdlist['Definitions'] = ['space']\n",
    "word_list = ['ape', 'blithe', 'turncoat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in text:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in text:\n",
    "    print(tag.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definitions(word_list):\n",
    "    df_word = pd.DataFrame(columns = ['Words', 'Parts of Speech', 'Definitions'])\n",
    "    url = 'https://www.dictionary.com/browse/'\n",
    "    \n",
    "    for word in word_list:\n",
    "        def_list = []\n",
    "        pos_list = []\n",
    "        results = requests.get(url + word, verify = False)\n",
    "        src = results.content\n",
    "        soup = bs(src, 'lxml')\n",
    "        text = soup.find_all(class_ = ['luna-pos', 'one-click-content'])\n",
    "        \n",
    "        for tag in text:\n",
    "            if tag.text.strip() in ['noun', 'verb', 'adverb', 'adjective']:\n",
    "                pos = tag.text.strip()\n",
    "            #Dealing with pos exceptions\n",
    "            elif tag.text.strip()[:4] == 'verb':\n",
    "                pos = 'verb'\n",
    "            else:\n",
    "                defi = tag.text.strip()\n",
    "                df_word['Definitions'] = [defi]\n",
    "                df_word['Parts of Speech'] = [pos]\n",
    "                df_word['Words'] = [word]\n",
    "                try:\n",
    "                    #print(df_word)\n",
    "                    df_tdlist = pd.concat([df_tdlist, df_word], axis = 0, ignore_index = True)\n",
    "                except:\n",
    "                    df_tdlist = df_word\n",
    "    \n",
    "    df_tdlist.drop_duplicates(inplace = True)\n",
    "    # Eliminates 'Disparaging and Offensive.' entries\n",
    "    m1 = (df_tdlist['Definitions'] == df_tdlist['Definitions'].shift(1))\n",
    "    m2 = df_tdlist['Definitions'].shift(1) == 'Disparaging and Offensive.'\n",
    "    df_tdlist = df_tdlist[~m2]\n",
    "    # Eliminates word senses\n",
    "    df_tdlist  = df_tdlist[df_tdlist['Definitions'].str[0].str.islower()]\n",
    "\n",
    "    print(df_tdlist)\n",
    "    return df_tdlist\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['blithe']\n",
    "df_tdlist = definitions(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(df_tdlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with 'sepcifically' in definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.merriam-webster.com/dictionary/'\n",
    "word = 'turncoat'\n",
    "results = requests.get(url + word)\n",
    "src = results.content\n",
    "soup = bs(src, 'lxml')\n",
    "text = soup.find_all(class_= ['num', 'letter', 'dtText', 'sdsense', 'important-blue-link'])\n",
    "\n",
    "pos_list = []\n",
    "def_list = []\n",
    "num = ''\n",
    "let = ''\n",
    "numletprev = ''\n",
    "\n",
    "for tag in text:\n",
    "    if tag.text.strip() in '1234567890':\n",
    "        num = tag.text.strip()\n",
    "    elif tag.text.strip() in 'abcdefghij':\n",
    "        let = tag.text.strip() \n",
    "    elif tag.text.strip() in ['noun', 'verb', 'adverb', 'adjective']:\n",
    "        pos = tag.text.strip()\n",
    "        if pos in pos_list:\n",
    "            break\n",
    "        pos_list.append(pos)\n",
    "    else:\n",
    "        if num+let == numletprev:\n",
    "            num = ''\n",
    "            let = '  '\n",
    "        defi = tag.text.strip()\n",
    "        if defi[:10] == 'especially':\n",
    "            esp = defi.split('\\n')\n",
    "            def_list[-1] = def_list[-1] + ' ' + esp[0]+ ':' +esp[1][1:]\n",
    "        if defi[:12] == 'specifically':\n",
    "            esp = defi.split('\\n')\n",
    "            def_list[-1] = def_list[-1] + ' ' + esp[0]+ \":\" +esp[1][1:]\n",
    "\n",
    "        else:\n",
    "            def_list.append(str(pos)+ ': ' + defi[2:])\n",
    "            numletprev = num+let\n",
    "            \n",
    "            \n",
    "            \n",
    "             \n",
    "print(def_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.merriam-webster.com/dictionary/'\n",
    "word = 'ape'\n",
    "results = requests.get(url + word)\n",
    "src = results.content\n",
    "soup = bs(src, 'lxml')\n",
    "text = soup.find_all(class_= ['sb-0', 'important-blue-link'])\n",
    "\n",
    "pos_list = []\n",
    "def_list = []\n",
    "num = ''\n",
    "let = ''\n",
    "numletprev = ''\n",
    "\n",
    "for tag in text:\n",
    "    if tag.text.strip() in ['noun', 'verb', 'adjective', 'adverb', 'pronoun']:\n",
    "        pos = tag.text.strip()\n",
    "    elif tag.text.strip() in ['transitive verb']:\n",
    "        pass\n",
    "    else:\n",
    "        def_list.append(tag.text.strip())\n",
    "            \n",
    "for part in def_list:        \n",
    "    print(part.split('\\n'))       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definitions(word_list):\n",
    "    url = 'https://www.merriam-webster.com/dictionary/'\n",
    "    \n",
    "    num = ''\n",
    "    let = ''\n",
    "    \n",
    "    numletprev = ''\n",
    "    \n",
    "    for word in word_list:\n",
    "        def_list = []\n",
    "        pos_list = []\n",
    "        results = requests.get(url + word)\n",
    "        src = results.content\n",
    "        soup = bs(src, 'lxml')\n",
    "        text = soup.find_all(class_= ['num', 'letter', 'dtText', 'sdsense', 'important-blue-link'])\n",
    "        \n",
    "        for tag in text:\n",
    "            if tag.text.strip() in '1234567890':\n",
    "                num = tag.text.strip()\n",
    "            elif tag.text.strip() in 'abcdefghij':\n",
    "                let = tag.text.strip() \n",
    "            elif tag.text.strip() in ['noun', 'verb', 'adverb', 'adjective']:\n",
    "                pos = tag.text.strip()\n",
    "                if pos in pos_list:\n",
    "                    break\n",
    "                pos_list.append(pos)\n",
    "            else:\n",
    "                if num+let == numletprev:\n",
    "                    num = ''\n",
    "                    let = '  '\n",
    "                defi = tag.text.strip()\n",
    "                if defi[:10] == 'especially':\n",
    "                    esp = defi.split('\\n')\n",
    "                    print(esp)\n",
    "                    def_list[-1] = def_list[-1] + ' ' + esp[0]+ ':' +esp[1][1:]\n",
    "                elif defi[:12] == 'specifically':\n",
    "                    esp = defi.split('\\n')\n",
    "                    print(esp)\n",
    "                    def_list[-1] = def_list[-1] + ' ' + esp[0]+ \":\" +esp[1][1:]\n",
    "\n",
    "                else:\n",
    "                    def_list.append(str(pos)+ ': ' + defi[2:])\n",
    "                    numletprev = num+let\n",
    "                    \n",
    "        df_word = pd.DataFrame(columns = ['Words', 'Definitions'])\n",
    "        df_word['Definitions'] = def_list\n",
    "        df_word['Words'] = [word]*len(def_list)\n",
    "        try:\n",
    "            #print(df_word)\n",
    "            df_tdlist = pd.concat([df_tdlist, df_word], axis = 0, ignore_index = True)\n",
    "        except:\n",
    "            df_tdlist = df_word\n",
    "    print(df_tdlist)\n",
    "    return df_tdlist.iat[11,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdlist.iat[11,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('ner_dataset 2.csv', encoding= 'unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
