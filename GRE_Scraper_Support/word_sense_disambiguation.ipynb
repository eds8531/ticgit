{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.wsd import lesk\n",
    "sent = 'The graffitti covered house was a blight on the neighborhood.'\n",
    "ambiguous = 'blight'\n",
    "lesk(sent, ambiguous).definition()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "AutoModelForSeq2SeqLM.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\")\n",
    "AutoTokenizer.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'question: which description describes the word \" java \" best in the following context?'\n",
    "descriptions:[  \" A drink consisting of an infusion of ground coffee beans \" , \" a platform-independent programming lanugage \" ,   \" an island in Indonesia to the south of Borneo \" ] \n",
    "context: 'I like to drink \" java \" in the morning .'\n",
    "\n",
    "\n",
    "example = tokenizer.tokenize(input, add_special_tokens=True)\n",
    "\n",
    "answer = model.generate(input_ids=example['input_ids'], \n",
    "                                attention_mask=example['attention_mask'], \n",
    "                                max_length=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\")\n",
    "\n",
    "input = \"\"\"question: which description describes the word \" java \" best in the following context? \\\n",
    "descriptions:[  \" A drink consisting of an infusion of ground coffee beans \" , \n",
    "                \" a platform-independent programming lanugage \"\n",
    "                ,  or \" an island in Indonesia to the south of Borneo \" ] \n",
    "context: I like to drink \" java \" in the morning .\"\"\"\n",
    "\n",
    "example = tokenizer.tokenize(input, add_special_tokens=True)\n",
    "\n",
    "#answer = model.generate(input_ids=example['input_ids'], attention_mask=example['attention_mask'], max_length=135)\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7862/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb25fff1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Text2TextGenerationPipeline\n",
    "\n",
    "pipe = Text2TextGenerationPipeline(model = AutoModelForSeq2SeqLM.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\"),\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jpelhaw/t5-word-sense-disambiguation\"))\n",
    "\n",
    "def wsd_gen(word, context, d1, d2, d3):\n",
    "            question = 'question: question: which description describes the word' + ' \" ' + word + ' \" '\n",
    "            descriptions_context = 'best in the following context? \\descriptions:[  \" ' + d1 + '\" , \" ' + d2 + ' \" , or \" '+ d3 + ' \" ] context: ' + context + \"'\"\n",
    "            raw_input = question + descriptions_context\n",
    "            output = pipe(raw_input)[0]['generated_text']\n",
    "            return output\n",
    "\n",
    "examples = [[\"beat\", 'The underdog team \"beat\" the reigning champion.', \" A main accent or rhythmic unit in music or poetry. \" ,  \" To strike repeatedly and violently so as to hurt or injure.\", \" To defeat (someone) in a game or other competitive situation. \"], [\"shell\", 'The first \"shell\" exploded in mid air taking out an enemy plane.', \"The hard protective outer case of a mollusk or crustacean.\", \"An explosive artillery projectile or bomb.\", \"Something resembling or likened to a shell because of its shape or its function as an outer case.\"]]\n",
    "\n",
    "word_mask = gr.inputs.Textbox(lines=1, placeholder= \"Enter word to disambiguate\", default=\"\", label = \"Based on the context, which description best matches this word: \")\n",
    "input_context = gr.inputs.Textbox(lines=1, placeholder=\"Enter context\", default=\"\", label = \"context: \")\n",
    "input_desc1 = gr.inputs.Textbox(lines=1, placeholder=\"Enter description\", default=\"\", label = \"description 1: \")\n",
    "input_desc2 = gr.inputs.Textbox(lines=1, placeholder=\"Enter description\", default=\"\", label = \"description 2: \")\n",
    "input_desc3 = gr.inputs.Textbox(lines=1, placeholder=\"Enter description\", default=\"\", label = \"description 3: \")\n",
    "\n",
    "gr.Interface(wsd_gen,\n",
    "            inputs = [word_mask , input_context, input_desc1, input_desc2, input_desc3],\n",
    "            outputs= \"textbox\",\n",
    "            examples = examples,\n",
    "            title = \"T5-Word Sense Disambiguation\", \n",
    "            description = \"Determines which 'sense' (meaning) of a word is activated by the use of the word in a particular context given three different descriptions.\",\n",
    "            theme = \"seafoam\",\n",
    "            article = \"This is an implementation of Google's T5-large model applied to Word Sense Disambiguation (WSD) and trained on the SemCor dataset. the SemCor dataset is a corpus made up of 352 documents for a total of 226,040 manually sense-annotated annotations used specifically used to train supervised WSD systems. The model used in this spaces was uploaded by Jan Philip Wahle (jpelhaw) in huggingface.\",\n",
    "            allow_flagging=\"never\").launch(inbrowser=True)\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.83810305595398"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
